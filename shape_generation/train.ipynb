{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMAsK81NmdcZZOEZ+LYsQPZ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QiuiS39J3B09"},"source":["# o-vton\n","## shape generation\n","### train"]},{"cell_type":"markdown","metadata":{"id":"R9kpBrCpDajD"},"source":["#### 필요한 패키지 설치"]},{"cell_type":"code","metadata":{"id":"AhHjtTiZ1bVp"},"source":["import os\n","import sys\n","\n","IS_COLAB = False\n","\n","if 'COLAB_GPU' in os.environ:\n","    IS_COLAB=True\n","else:\n","    IS_COLAB=False\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGUgHBDspWFx","executionInfo":{"elapsed":1684,"status":"ok","timestamp":1609073189896,"user":{"displayName":"조원양","photoUrl":"","userId":"08900164231215276163"},"user_tz":-540},"outputId":"a6740e12-6b8e-455e-c645-8182776fb15f"},"source":["!nvcc --version\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2019 NVIDIA Corporation\n","Built on Sun_Jul_28_19:07:16_PDT_2019\n","Cuda compilation tools, release 10.1, V10.1.243\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mgXQLsjgpV8S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zy0hs_zVDdro","executionInfo":{"elapsed":19878,"status":"ok","timestamp":1609073208101,"user":{"displayName":"조원양","photoUrl":"","userId":"08900164231215276163"},"user_tz":-540},"outputId":"18d20cf5-9b3e-404f-e765-c3ab212f2b76"},"source":["!pip install dominate\n","!pip install av\n","# install dependencies: \n","!pip install pyyaml==5.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting dominate\n","  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n","Installing collected packages: dominate\n","Successfully installed dominate-2.6.0\n","Collecting av\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n","\u001b[K     |████████████████████████████████| 36.9MB 1.3MB/s \n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-8.0.2\n","Collecting pyyaml==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 4.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44075 sha256=f9565c8a4febf9db90375657c1a8e00fb975297d3de399889b0674eeae1b9aa5\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","1.7.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"ce9UBYpeD2cB","executionInfo":{"elapsed":31342,"status":"ok","timestamp":1609073219575,"user":{"displayName":"조원양","photoUrl":"","userId":"08900164231215276163"},"user_tz":-540},"outputId":"40c28db8-5cc8-4a79-f1df-563e743fa318"},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.7\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.3+cu101)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.2)\n","Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.2.post20201218)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (8.0.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.4.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (51.0.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (5.1)\n","Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (0.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (1.19.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.3.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.36.2)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.10.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.32.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2) (2.0.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (3.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.7.4.3)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"vxIO4MJOU5fZ"},"source":["# console에서 다음 작업 진행할 것.\n","\n","# !git clone https://github.com/wonyangcho/detectron2.git\n","# !cd detectron2\n","# !git checkout develop\n","# !git pull\n","# !cd ..\n","# !git clone https://github.com/wonyangcho/Image-Based-Virtual-Try-on-Network-from-Unpaired-Data.git o-vton\n","# !cd o-vton\n","# !git checkout develop\n","# !git pull\n","# !cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8_vAN8PC1-3d"},"source":["if IS_COLAB == True:\n","    from google.colab import drive\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pYVOKkK02Esk","executionInfo":{"elapsed":31326,"status":"ok","timestamp":1609073219578,"user":{"displayName":"조원양","photoUrl":"","userId":"08900164231215276163"},"user_tz":-540},"outputId":"0afc4f88-608f-4f4c-e52c-92002accdee9"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun Dec 27 12:47:39 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    30W / 250W |     10MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XFMgPSDW4JcL"},"source":["#### 데이터 불러오기"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ldEsUhMm4Nf6","outputId":"21e9e716-0ffa-4d38-b8d1-a6c17e377505"},"source":["from pathlib import Path\n","\n","my_file = Path(\"/content/dataset\")\n","if my_file.is_dir() == False:\n","  !wget -O o-vton-dataset.zip https://www.dropbox.com/s/3kexhszm15z8j2d/o-vton-dataset_train.zip?dl=0\n","  !unzip -o -q o-vton-dataset.zip \n","  !rm o-vton-dataset.zip\n","!ls ./dataset\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-12-27 12:47:40--  https://www.dropbox.com/s/q58xuki764dnh06/o-vton-dataset.zip?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/q58xuki764dnh06/o-vton-dataset.zip [following]\n","--2020-12-27 12:47:40--  https://www.dropbox.com/s/raw/q58xuki764dnh06/o-vton-dataset.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com/cd/0/inline/BF1pAPOUglcx2mfH-Kbuz8LpokDMND39wjrvZIqEuiJgwsVE9ZouZb6hCkhioF95r6EZAicEwoUHHsXh1Ow0zetlSBAO_TeRRWDjgYaio3-xZcTKgwWBgFfgTjseJvgbHSA/file# [following]\n","--2020-12-27 12:47:40--  https://uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com/cd/0/inline/BF1pAPOUglcx2mfH-Kbuz8LpokDMND39wjrvZIqEuiJgwsVE9ZouZb6hCkhioF95r6EZAicEwoUHHsXh1Ow0zetlSBAO_TeRRWDjgYaio3-xZcTKgwWBgFfgTjseJvgbHSA/file\n","Resolving uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com (uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com (uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BF2FSbOQtz0r735DqWoq3KyI7YdWJqq_8KRhfqsZ-EeUHGsuRlwCeVo2gzLN8U8wG7IvCRUh04b5ja6LVlHPmZKm5Qj1VD81NlDyzAPhgCMIGWGwr9iFS9iFmceVIag23wTGeK5BRsOmhMqynIple_tsJKRY6inFkeeOsOCF0IXkuz2HiU5m3ltptEAF3EJ9F5nh3iiObFo1TqkFlJ2v6Yrc2I0kN64emet8waqF0ROOQHSDjt71ODjdWZ6pkPI6NNCIcqyPmhvsIg8-5NfQ3g1bJod9LlpB1rMwjJb6xpevJNWZahw6eV4_PI4CWuSJI_q2VRAkBw2205F0fIHc_u2czIeGsPpj3BAtku0zAZphIg/file [following]\n","--2020-12-27 12:47:41--  https://uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com/cd/0/inline2/BF2FSbOQtz0r735DqWoq3KyI7YdWJqq_8KRhfqsZ-EeUHGsuRlwCeVo2gzLN8U8wG7IvCRUh04b5ja6LVlHPmZKm5Qj1VD81NlDyzAPhgCMIGWGwr9iFS9iFmceVIag23wTGeK5BRsOmhMqynIple_tsJKRY6inFkeeOsOCF0IXkuz2HiU5m3ltptEAF3EJ9F5nh3iiObFo1TqkFlJ2v6Yrc2I0kN64emet8waqF0ROOQHSDjt71ODjdWZ6pkPI6NNCIcqyPmhvsIg8-5NfQ3g1bJod9LlpB1rMwjJb6xpevJNWZahw6eV4_PI4CWuSJI_q2VRAkBw2205F0fIHc_u2czIeGsPpj3BAtku0zAZphIg/file\n","Reusing existing connection to uc926e1728c5c0a24b9b565403e8.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21346977718 (20G) [application/zip]\n","Saving to: ‘o-vton-dataset.zip’\n","\n","o-vton-dataset.zip  100%[===================>]  19.88G  72.1MB/s    in 4m 50s  \n","\n","2020-12-27 12:52:32 (70.1 MB/s) - ‘o-vton-dataset.zip’ saved [21346977718/21346977718]\n","\n","train_densepose  train_img  train_label\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7iwRYE8N8OeW"},"source":["#### google drive 연결"]},{"cell_type":"code","metadata":{"id":"WNYo5uHp2JVC"},"source":["if IS_COLAB == True:\n","    drive.mount('/content/drive')\n","    !ls \"/content/drive/My Drive/02_o-vton/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aymgWlUq33Mh"},"source":["#### path 설정"]},{"cell_type":"code","metadata":{"id":"9mdwE-4q2KFV"},"source":["if IS_COLAB == True:\n","  sys.path.append(\"/content/drive/My Drive/02_o-vton/source/shape_generation\")\n","  sys.path.append(\"/content/o-vton/shape_generation\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ssmqjfbO6266"},"source":["#### 관련 모듈 불러오기 "]},{"cell_type":"code","metadata":{"id":"1d017aLv31G0"},"source":["from options.train_options_colab import TrainOptionsColab\n","from util.visualizer import Visualizer\n","import util.util as util\n","from models.models import create_model\n","from data.ov_train_dataset import RegularDataset\n","import time\n","import os\n","import numpy as np\n","import torch\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from collections import OrderedDict\n","from subprocess import call\n","import fractions\n","from torch.utils.tensorboard import SummaryWriter\n","from multiprocessing import Process\n","import matplotlib\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWSEOs3lTc8c"},"source":["#### checkpoint 경로 확인"]},{"cell_type":"code","metadata":{"id":"dT44-QOSZUy1"},"source":["!ls /content/drive/MyDrive/02_o-vton/source/shape_generation/checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTdoLtM2oKrv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTg102Pe7BUl"},"source":["#### main"]},{"cell_type":"code","metadata":{"id":"9fo75I8c6_Lx"},"source":["def lcm(a, b): return abs(a * b)/fractions.gcd(a, b) if a and b else 0\n","\n","def main():\n","    trainOption = TrainOptionsColab()\n","    trainOption.initialize()\n","\n","    opt = trainOption.parser\n","   \n","\n","    opt.print_freq = lcm(opt.print_freq, opt.batchSize)\n","    if opt.debug:\n","        opt.display_freq = 1\n","        opt.print_freq = 1\n","        opt.niter = 1\n","        opt.niter_decay = 0\n","        opt.max_dataset_size = 10\n","    \n","    opt.checkpoints_dir = \"/content/drive/My Drive/02_o-vton/source/shape_generation/checkpoints\"\n","    opt.dataroot = \"./dataset\"\n","    opt.continue_train = False #이전 checkpoint부터 학습을 하고 싶으면 True.\n","    opt.gpu_ids = \"0\"\n","    opt.nThreads = 0\n","\n","    iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n","    if opt.continue_train:\n","        try:\n","            start_epoch, epoch_iter = np.loadtxt(\n","                iter_path, delimiter=',', dtype=int)\n","        except:\n","            start_epoch, epoch_iter = 1, 0\n","        print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))\n","    else:\n","        start_epoch, epoch_iter = 1, 0\n","\n","   \n","\n","    # NEW DATALOADER\n","    augment = {}\n","\n","   \n","    augment['1'] = transforms.Compose(\n","        [\n","            transforms.ToPILImage(),\n","            transforms.RandomAffine(degrees=10, translate=(\n","                0.1, 0.1), scale=(0.8, 1.2), shear=20),\n","            transforms.ToTensor()])  # change to [C, H, W]\n","\n","    augment['2'] = transforms.Compose(\n","        [\n","            transforms.ToTensor()])  # change to [C, H, W]\n","\n","    train_dataset = RegularDataset(opt, augment)\n","\n","    train_dataloader = DataLoader(train_dataset,\n","                                batch_size=opt.batchSize,\n","                                shuffle=True,\n","                                num_workers=int(opt.nThreads),\n","                                pin_memory=True)\n","  \n","\n","\n","    dataset_size = len(train_dataset)\n","    print('#training images = %d' % dataset_size)\n","\n","    # FOR DEBUGGING\n","    print(\" #Checking  the dimension and type of data\")\n","    for key in train_dataset[0].keys():\n","        try:\n","            x = train_dataset[0][key]\n","            print(\"name of the input and shape -- > \", key, x.shape)\n","            print(\"type,dtype,and min max -- >\", type(x),\n","                x.dtype, torch.min(x), torch.max(x))\n","        except Exception as e:\n","            print(\"name of the input -- > \", key, train_dataset[0][key])\n","        print('----------------')\n","\n","    dataset_size = len(train_dataset)\n","    print('#training images = %d' % dataset_size)\n","\n","    # Initialize Networks\n","    model = create_model(opt)\n","\n","    # Training Visualizer\n","    visualizer = Visualizer(opt)\n","\n","    # Optimizers\n","    optimizer_G, optimizer_D = model.module.optimizer_G, model.module.optimizer_D\n","\n","    # Train related additional details\n","    total_steps = (start_epoch-1) * dataset_size + epoch_iter\n","    display_delta = total_steps % opt.display_freq\n","    print_delta = total_steps % opt.print_freq\n","    save_delta = total_steps % opt.save_latest_freq\n","\n","\n","    for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n","        epoch_start_time = time.time()\n","        if epoch != start_epoch:\n","            epoch_iter = epoch_iter % dataset_size\n","        for i, data in enumerate(train_dataloader, start=epoch_iter):\n","            if total_steps % opt.print_freq == print_delta:\n","                iter_start_time = time.time()\n","            total_steps += opt.batchSize\n","            epoch_iter += opt.batchSize\n","\n","            # whether to collect output images\n","            save_fake = total_steps % opt.display_freq == display_delta\n","\n","            ############## Forward Pass ######################\n","            # Reference Purpose\n","            # input_dict = {'seg_map': A_tensor, 'dense_map': dense_img, 'target': B_tensor, 'seg_map_path': A_path,\n","            # 'target_path': A_path, 'densepose_path': dense_path }\n","            # print( data['seg_mask'].shape)\n","            losses, generated = model(\n","                data['seg_map'], data['dense_map'], data['target'], data['seg_mask'], infer=save_fake)\n","\n","            # sum per device losses\n","            losses = [torch.mean(x) if not isinstance(x, int)\n","                    else x for x in losses]\n","            loss_dict = dict(zip(model.module.loss_names, losses))\n","\n","            # calculate final loss scalar\n","            loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n","            loss_G = loss_dict['G_GAN'] + loss_dict.get('G_CE', 0)\n","\n","            ############### Backward Pass ####################\n","            # update generator weights\n","            optimizer_G.zero_grad()\n","            loss_G.backward()\n","            optimizer_G.step()\n","\n","            # update discriminator weights\n","            optimizer_D.zero_grad()\n","            loss_D.backward()\n","            optimizer_D.step()\n","\n","            ############## Display results and errors ##########\n","            # print out errors\n","            if total_steps % opt.print_freq == print_delta:\n","                errors = {k: v.data.item() if not isinstance(\n","                    v, int) else v for k, v in loss_dict.items()}\n","                t = (time.time() - iter_start_time) / opt.print_freq\n","                visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n","                visualizer.plot_current_errors(errors, total_steps)\n","                #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"])\n","\n","            # display output images\n","            if save_fake:\n","                visuals = OrderedDict([('input_label', util.tensor2label(data['seg_map'][0], opt.label_nc)),\n","                                    ('synthesized_image', util.tensor2label(\n","                                        generated.data[0], opt.label_nc)),\n","                                    ('real_image', util.tensor2label(data['target'][0], opt.label_nc))])\n","                visualizer.display_current_results(visuals, epoch, total_steps)\n","\n","            # save latest model\n","            if total_steps % opt.save_latest_freq == save_delta:\n","                print('saving the latest model (epoch %d, total_steps %d)' %\n","                    (epoch, total_steps))\n","                model.module.save('latest')\n","                np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n","\n","            if epoch_iter >= dataset_size:\n","                break\n","\n","        # end of epoch\n","        iter_end_time = time.time()\n","        print('End of epoch %d / %d \\t Time Taken: %d sec' %\n","            (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n","\n","        # save model for this epoch\n","        if epoch % opt.save_epoch_freq == 0:\n","            print('saving the model at the end of epoch %d, iters %d' %\n","                (epoch, total_steps))\n","            model.module.save('latest')\n","            model.module.save(epoch)\n","            np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n","\n","        # linearly decay learning rate after certain iterations\n","        if epoch > opt.niter:\n","            model.module.update_learning_rate()\n","        \n","\n","if __name__ == '__main__':\n","    # torch.multiprocessing.set_start_method('spawn')\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wnCKtv80D-lu"},"source":[""],"execution_count":null,"outputs":[]}]}